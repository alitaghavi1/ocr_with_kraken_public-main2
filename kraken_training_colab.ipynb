{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kraken OCR Training on Google Colab\n",
        "\n",
        "This notebook allows you to train/fine-tune Kraken OCR models for Arabic/Persian handwritten text recognition.\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. **Enable GPU**: Go to `Runtime` > `Change runtime type` > Select `T4 GPU` (or better)\n",
        "2. **Upload your data** to Google Drive before running\n",
        "3. **Run cells in order** from top to bottom\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check GPU and Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive\n",
        "\n",
        "Your training data and models will be stored in Google Drive so they persist between sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory in Drive\n",
        "import os\n",
        "PROJECT_DIR = '/content/drive/MyDrive/kraken_ocr_training'\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{PROJECT_DIR}/models', exist_ok=True)\n",
        "os.makedirs(f'{PROJECT_DIR}/training_data', exist_ok=True)\n",
        "os.makedirs(f'{PROJECT_DIR}/checkpoints', exist_ok=True)\n",
        "\n",
        "print(f\"Project directory: {PROJECT_DIR}\")\n",
        "print(\"\\nDirectory structure created:\")\n",
        "print(\"  - models/          (store base and fine-tuned models)\")\n",
        "print(\"  - training_data/   (upload your .png + .gt.txt pairs here)\")\n",
        "print(\"  - checkpoints/     (training checkpoints saved here)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Kraken OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Kraken with CUDA support\n",
        "!pip install kraken --quiet\n",
        "\n",
        "# Verify installation\n",
        "!ketos --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Download Base Model (Optional)\n",
        "\n",
        "If you want to fine-tune from a pre-trained model, download one here. Skip if you already have a model in Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List available models\n",
        "!kraken list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download a base model (uncomment and modify as needed)\n",
        "# For Arabic text:\n",
        "# !kraken get arabic_best -o {PROJECT_DIR}/models/\n",
        "\n",
        "# Or copy your own model from local upload\n",
        "# If you uploaded a model to Colab, copy it to Drive:\n",
        "# !cp /content/your_model.mlmodel {PROJECT_DIR}/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Upload Training Data\n",
        "\n",
        "**Option A**: Upload directly to Google Drive (recommended)\n",
        "- Upload your training data to `kraken_ocr_training/training_data/` in Google Drive\n",
        "- Each training sample needs: `image.png` + `image.gt.txt`\n",
        "\n",
        "**Option B**: Upload a ZIP file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B: Upload and extract a ZIP file\n",
        "from google.colab import files\n",
        "\n",
        "# Uncomment to upload a ZIP file:\n",
        "# uploaded = files.upload()\n",
        "# !unzip -o *.zip -d {PROJECT_DIR}/training_data/\n",
        "\n",
        "# Check what's in training_data\n",
        "!ls -la {PROJECT_DIR}/training_data/ | head -20\n",
        "\n",
        "# Count training files\n",
        "import glob\n",
        "png_files = glob.glob(f'{PROJECT_DIR}/training_data/*.png')\n",
        "gt_files = glob.glob(f'{PROJECT_DIR}/training_data/*.gt.txt')\n",
        "print(f\"\\nFound {len(png_files)} images and {len(gt_files)} ground truth files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Configuration\n",
        "\n",
        "Adjust these parameters based on your needs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Training Configuration { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Training Mode\n",
        "TRAINING_MODE = \"finetune\"  #@param [\"finetune\", \"scratch\", \"continue\"]\n",
        "\n",
        "#@markdown ### Paths\n",
        "BASE_MODEL = \"/content/drive/MyDrive/kraken_ocr_training/models/all_arabic_scripts.mlmodel\"  #@param {type:\"string\"}\n",
        "TRAINING_DATA = \"/content/drive/MyDrive/kraken_ocr_training/training_data\"  #@param {type:\"string\"}\n",
        "OUTPUT_MODEL = \"/content/drive/MyDrive/kraken_ocr_training/checkpoints/model\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Hyperparameters\n",
        "BATCH_SIZE = 8  #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "EPOCHS = 50  #@param {type:\"slider\", min:10, max:200, step:10}\n",
        "LEARNING_RATE = 0.0001  #@param {type:\"number\"}\n",
        "EARLY_STOPPING = 10  #@param {type:\"slider\", min:3, max:20, step:1}\n",
        "\n",
        "#@markdown ### Options\n",
        "USE_AUGMENTATION = True  #@param {type:\"boolean\"}\n",
        "LR_SCHEDULE = \"reduceonplateau\"  #@param [\"reduceonplateau\", \"cosine\", \"exponential\", \"1cycle\"]\n",
        "\n",
        "print(\"Configuration saved!\")\n",
        "print(f\"  Mode: {TRAINING_MODE}\")\n",
        "print(f\"  Base model: {BASE_MODEL}\")\n",
        "print(f\"  Training data: {TRAINING_DATA}\")\n",
        "print(f\"  Output: {OUTPUT_MODEL}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Validate Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# Find all training images\n",
        "images = glob.glob(f'{TRAINING_DATA}/*.png') + glob.glob(f'{TRAINING_DATA}/*.jpg')\n",
        "print(f\"Found {len(images)} training images\")\n",
        "\n",
        "# Validate ground truth files\n",
        "valid_pairs = []\n",
        "missing_gt = []\n",
        "\n",
        "for img in images:\n",
        "    gt_file = Path(img).with_suffix('.gt.txt')\n",
        "    if gt_file.exists():\n",
        "        valid_pairs.append(img)\n",
        "    else:\n",
        "        missing_gt.append(img)\n",
        "\n",
        "print(f\"Valid image+text pairs: {len(valid_pairs)}\")\n",
        "\n",
        "if missing_gt:\n",
        "    print(f\"\\nWARNING: {len(missing_gt)} images missing ground truth files\")\n",
        "    print(\"First 5 missing:\")\n",
        "    for m in missing_gt[:5]:\n",
        "        print(f\"  - {os.path.basename(m)}\")\n",
        "\n",
        "if len(valid_pairs) == 0:\n",
        "    print(\"\\nERROR: No valid training pairs found!\")\n",
        "    print(\"Make sure each .png has a matching .gt.txt file\")\n",
        "else:\n",
        "    print(f\"\\nReady to train with {len(valid_pairs)} samples!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Start Training\n",
        "\n",
        "This cell runs the actual training. It will:\n",
        "- Save checkpoints to Google Drive (so you don't lose progress if disconnected)\n",
        "- Display training progress with accuracy metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Build training command\n",
        "cmd = [\n",
        "    'ketos',\n",
        "    '-d', 'cuda:0',\n",
        "    'train',\n",
        "    '-o', OUTPUT_MODEL,\n",
        "    '-f', 'path',\n",
        "    '-B', str(BATCH_SIZE),\n",
        "    '-N', str(EPOCHS),\n",
        "    '--lag', str(EARLY_STOPPING),\n",
        "    '-r', str(LEARNING_RATE),\n",
        "    '--schedule', LR_SCHEDULE,\n",
        "]\n",
        "\n",
        "# Add augmentation if enabled\n",
        "if USE_AUGMENTATION:\n",
        "    cmd.append('--augment')\n",
        "\n",
        "# Add model based on training mode\n",
        "if TRAINING_MODE == 'finetune' and os.path.exists(BASE_MODEL):\n",
        "    cmd.extend(['-i', BASE_MODEL, '--resize', 'union'])\n",
        "    print(f\"Fine-tuning from: {BASE_MODEL}\")\n",
        "elif TRAINING_MODE == 'continue' and os.path.exists(f'{OUTPUT_MODEL}_best.mlmodel'):\n",
        "    cmd.extend(['-i', f'{OUTPUT_MODEL}_best.mlmodel', '--resize', 'add'])\n",
        "    print(f\"Continuing from: {OUTPUT_MODEL}_best.mlmodel\")\n",
        "else:\n",
        "    print(\"Training from scratch\")\n",
        "\n",
        "# Add training data pattern\n",
        "cmd.append(f'{TRAINING_DATA}/*.png')\n",
        "\n",
        "print(f\"\\nCommand: {' '.join(cmd[:10])}...\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting training... (this may take a while)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Run training\n",
        "!{' '.join(cmd)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Check Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# List all generated models\n",
        "checkpoint_dir = os.path.dirname(OUTPUT_MODEL)\n",
        "models = glob.glob(f'{checkpoint_dir}/*.mlmodel')\n",
        "\n",
        "print(\"Generated models:\")\n",
        "for m in sorted(models):\n",
        "    size_mb = os.path.getsize(m) / (1024*1024)\n",
        "    print(f\"  - {os.path.basename(m)} ({size_mb:.1f} MB)\")\n",
        "\n",
        "# Find best model\n",
        "best_model = f'{OUTPUT_MODEL}_best.mlmodel'\n",
        "if os.path.exists(best_model):\n",
        "    print(f\"\\nBest model: {best_model}\")\n",
        "    print(\"This is the model you should use for inference.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test OCR on a sample image\n",
        "import glob\n",
        "import random\n",
        "\n",
        "# Get a random test image\n",
        "test_images = glob.glob(f'{TRAINING_DATA}/*.png')\n",
        "if test_images:\n",
        "    test_image = random.choice(test_images)\n",
        "    print(f\"Testing on: {os.path.basename(test_image)}\")\n",
        "    \n",
        "    # Show the image\n",
        "    from IPython.display import Image, display\n",
        "    display(Image(filename=test_image, width=600))\n",
        "    \n",
        "    # Run OCR\n",
        "    best_model = f'{OUTPUT_MODEL}_best.mlmodel'\n",
        "    if os.path.exists(best_model):\n",
        "        print(\"\\nOCR Output:\")\n",
        "        !kraken -i \"{test_image}\" output.txt binarize segment -bl ocr -m \"{best_model}\"\n",
        "        !cat output.txt\n",
        "        \n",
        "        # Show ground truth for comparison\n",
        "        gt_file = test_image.replace('.png', '.gt.txt')\n",
        "        if os.path.exists(gt_file):\n",
        "            print(\"\\nGround Truth:\")\n",
        "            !cat \"{gt_file}\"\n",
        "else:\n",
        "    print(\"No test images found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Download the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Model is already in Google Drive - access it directly\n",
        "print(f\"Your model is saved at: {OUTPUT_MODEL}_best.mlmodel\")\n",
        "print(\"You can access it from Google Drive.\")\n",
        "\n",
        "# Option 2: Download directly to your computer\n",
        "from google.colab import files\n",
        "\n",
        "best_model = f'{OUTPUT_MODEL}_best.mlmodel'\n",
        "if os.path.exists(best_model):\n",
        "    print(\"\\nDownloading best model...\")\n",
        "    files.download(best_model)\n",
        "else:\n",
        "    print(\"Best model not found. Check if training completed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Tips for Long Training Sessions\n",
        "\n",
        "1. **Keep the browser tab open** - Colab disconnects after inactivity\n",
        "2. **Use Colab Pro** for longer sessions and better GPUs\n",
        "3. **Checkpoints are saved to Drive** - you can resume if disconnected\n",
        "4. **To resume training**: Change `TRAINING_MODE` to `continue` and re-run\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "- **Out of memory**: Reduce `BATCH_SIZE` to 4 or 2\n",
        "- **Training too slow**: Enable GPU in Runtime settings\n",
        "- **Disconnected**: Change mode to `continue` and re-run from cell 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Continue Training (After Disconnect)\n",
        "\n",
        "If you got disconnected, run these cells to continue:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick reconnect and continue\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Reinstall kraken\n",
        "!pip install kraken --quiet\n",
        "\n",
        "# Set paths (update these to match your setup)\n",
        "PROJECT_DIR = '/content/drive/MyDrive/kraken_ocr_training'\n",
        "TRAINING_DATA = f'{PROJECT_DIR}/training_data'\n",
        "OUTPUT_MODEL = f'{PROJECT_DIR}/checkpoints/model'\n",
        "CHECKPOINT = f'{OUTPUT_MODEL}_best.mlmodel'  # Latest checkpoint\n",
        "\n",
        "# Continue training from checkpoint\n",
        "!ketos -d cuda:0 train \\\n",
        "    -o {OUTPUT_MODEL} \\\n",
        "    -f path \\\n",
        "    -B 8 \\\n",
        "    -N 50 \\\n",
        "    --lag 10 \\\n",
        "    -r 0.0001 \\\n",
        "    --schedule reduceonplateau \\\n",
        "    --augment \\\n",
        "    -i {CHECKPOINT} \\\n",
        "    --resize add \\\n",
        "    '{TRAINING_DATA}/*.png'"
      ]
    }
  ]
}
